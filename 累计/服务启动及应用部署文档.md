# 启动命令

## zookeeper命令

```powershell
zookeeper启动命令         
        /export/servers/zookeeper-3.4.9/bin/zServer.sh start 
zookeeper查看启动状态
        /export/servers/zookeeper-3.4.9/bin/zServer.sh status
```

## hadoop命令

```powershell
启动hadoop集群
        # 会登录进所有的worker启动相关进行, 也可以手动进行, 但是没必要
        /export/servers/hadoop-3.1.1/sbin/start-dfs.sh
        /export/servers/hadoop-3.1.1/sbin/start-yarn.sh
        mapred --daemon start historyserver
成功检查
        此时便可以通过如下三个URL访问Hadoop了
        - HDFS: `http://192.168.174.100:50070/dfshealth.html#tab-overview`
        - Yarn: `http://192.168.174.100:8088/cluster`
```

## hdfs命令

```powershell

HDFS
    --启动命令
      sbin/start-dfs.sh
      sbin/start-yarn.sh
    --shell的操作命令
    hdfs dfs -ls / 查看根路径下面的文件或者文件夹
    hdfs dfs -mkdir -p /xx/xxx    在hdfs上面递归的创建文件夹
    hdfs dfs -moveFromLocal sourceDir(本地磁盘的文件或者文件夹的路径) destDir（hdfs的路径）
    hdfs dfs -mv hdfsourceDir hdfsDestDir 移动hdfs上的文件位置
    hdfs dfs -put localDir hdfsDir    将本地文件系统的文件或者文件夹放到hdfs上面去
    hdfs dfs -appendToFile    a.txt b.txt /hello.txt 将多个小文件合并为一个大文件
    hdfs dfs -cat hdfsFile    查看hdfs的文件内容
    hdfs dfs -cp hdfsSourceDir hdfsDestDir    拷贝文件或者文件夹
    hdfs dfs -rm [-r] File[Dir]    （递归）删除文件或者文件夹
    hadoop fs -rm -r -skipTrash /folder_name   删除目录folder_name
    --从hdfs拷贝到本地
    hadoop fs -du -s -h /jinguo
    hadoop fs -du -h /jinguo
    ---setrep：设置 HDFS 中文件的副本数量
    hadoop fs -setrep 10 /jinguo/shuguo.txt
    
    hadoop fs -copyToLocal /sanguo/shuguo.txt ./  
    hadoop fs -get/sanguo/shuguo.txt ./shuguo2.txt
    --du 统计文件夹的大小信息
    
    hdfs的权限管理两个命令
    hdfs dfs -chmod -R 777 /xxx 更改文件（目录）访问权限
    hdfs dfs -chown    -R hadoop:hadoop /xxx 更改文件（目录）组访问权限 
    
    --修改权限
    关闭集群
    cd /export/servers/hadoop-3.1.1/etc/hadoop
    vim hdfs-site.xml
        三台机器同步
    <property>
        <name>dfs.permissions.enabled</name>
        <value>true</value>
    </property>
    --文件合并
    可以通过命令行将很多的 hdfs 文件合并成一个大文件下载到本地
    hdfs dfs -getmerge /config/*.xml ./hello.xml
```

## 集群拷贝命令

```powershell
    scp hdfs-site.xml node02:$PWD
    scp hdfs-site.xml node03:$PWD
```

## hive启动命令    

```powershell
Hive数据仓库
    --启动HIve
    bin/hive
```

## hbase启动命令

```powershell
hbase启动
    --启动hbase集群
    hbase-all.sh
```

## flink集群启动命令及任务启动命令

```powershell
flink
    --启动flink
    start-cluster.sh
    ./flink run -c com.guigu.wc.StreamWordCount /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar /applog/flink/input.txt /applog/flink/output.csv
    ./flink run -m yarn-cluster -c com.guigu.wc.StreamWordCount /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar /applog/flink/input.txt /applog/flink/output.csv
    
    ./flink run -c com.guigu.wc.StreamWordCount_socket /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar 192.168.75.100 7777 /applog/flink/output.csv
    ./flink run -m yarn-cluster -c com.guigu.wc.StreamWordCount_socket /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar 192.168.75.100 7777 /applog/flink/output.csv
    bin/flink run /export/servers/flink-1.6.0/examples/batch/WordCount.jar --input hdfs://node-1:9000/test/input/wordcount.txt --output hdfs://node-1:9000/test/output/result.txt
```

## kafka后台启动命令

```powershell

kafka启动
    --启动
    bin/kafka-server-start.sh -daemon config/server.properties
```

## mapreduce

```powershell
--任务启动hive
yarn jar hadoop_hdfs_operate‐1.0‐SNAPSHOT.jar
cn.itcast.hdfs.demo1.JobMain
--应用提交
hadoop jar jar_name MainClass
```

## spark命令

### Local模式

```powershell
--启动 Local 环境 
bin/spark-shell
--验证Local环境是否成功
http://192.168.75.100:4040/jobs/
--程序验证
scala> sc.textFile("data/word.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect
--结果
res1: Array[(String, Int)] = Array((Hello,2), (Scala,1), (Spark,1))
--应用提交
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master local[2] \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

### standalone模式

```powershell
--启动历史服务
sbin/start-history-server.sh
--启动集群
sbin/start-all.sh
--启动节点--高可用主备模式
sbin/start-master.sh
--停止集群
sbin/stop-all.sh
--应用提交
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://linux1:7077 \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
--提交应用到高可用集群
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://linux1:7077,linux2:7077 \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10

```

## Yarn模式

```powershell
--启动历史服务
sbin/start-history-server.sh
--启动集群
sbin/start-all.sh
--应用提交
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode client \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

## window模式

```powershell
--启动
bin 目录中的 spark-shell.cmd
--应用提交
spark-submit --class org.apache.spark.examples.SparkPi --master
local[2] ../examples/jars/spark-examples_2.12-3.0.0.jar 10
```
