---
typora-root-url: img_install
---

# 启动命令

## zookeeper命令

```powershell
zookeeper启动命令         
        /export/servers/zookeeper-3.4.9/bin/zServer.sh start 
zookeeper查看启动状态
        /export/servers/zookeeper-3.4.9/bin/zServer.sh status
```

## hadoop命令

```powershell
启动hadoop集群
        # 会登录进所有的worker启动相关进行, 也可以手动进行, 但是没必要
        /export/servers/hadoop-3.1.1/sbin/start-dfs.sh
        /export/servers/hadoop-3.1.1/sbin/start-yarn.sh
        mapred --daemon start historyserver
成功检查
        此时便可以通过如下三个URL访问Hadoop了
        - HDFS: `http://192.168.174.100:50070/dfshealth.html#tab-overview`
        - Yarn: `http://192.168.174.100:8088/cluster`
```

## hdfs命令

```powershell

HDFS
    --启动命令
      sbin/start-dfs.sh
      sbin/start-yarn.sh
    --shell的操作命令
    hdfs dfs -ls / 查看根路径下面的文件或者文件夹
    hdfs dfs -mkdir -p /xx/xxx    在hdfs上面递归的创建文件夹
    hdfs dfs -moveFromLocal sourceDir(本地磁盘的文件或者文件夹的路径) destDir（hdfs的路径）
    hdfs dfs -mv hdfsourceDir hdfsDestDir 移动hdfs上的文件位置
    hdfs dfs -put localDir hdfsDir    将本地文件系统的文件或者文件夹放到hdfs上面去
    hdfs dfs -appendToFile    a.txt b.txt /hello.txt 将多个小文件合并为一个大文件
    hdfs dfs -cat hdfsFile    查看hdfs的文件内容
    hdfs dfs -cp hdfsSourceDir hdfsDestDir    拷贝文件或者文件夹
    hdfs dfs -rm [-r] File[Dir]    （递归）删除文件或者文件夹
    hadoop fs -rm -r -skipTrash /folder_name   删除目录folder_name
    --从hdfs拷贝到本地
    hadoop fs -du -s -h /jinguo
    hadoop fs -du -h /jinguo
    ---setrep：设置 HDFS 中文件的副本数量
    hadoop fs -setrep 10 /jinguo/shuguo.txt
    
    hadoop fs -copyToLocal /sanguo/shuguo.txt ./  
    hadoop fs -get/sanguo/shuguo.txt ./shuguo2.txt
    --du 统计文件夹的大小信息
    
    hdfs的权限管理两个命令
    hdfs dfs -chmod -R 777 /xxx 更改文件（目录）访问权限
    hdfs dfs -chown    -R hadoop:hadoop /xxx 更改文件（目录）组访问权限 
    
    --修改权限
    关闭集群
    cd /export/servers/hadoop-3.1.1/etc/hadoop
    vim hdfs-site.xml
        三台机器同步
    <property>
        <name>dfs.permissions.enabled</name>
        <value>true</value>
    </property>
    --文件合并
    可以通过命令行将很多的 hdfs 文件合并成一个大文件下载到本地
    hdfs dfs -getmerge /config/*.xml ./hello.xml
```

## 集群拷贝命令

```powershell
    scp hdfs-site.xml node02:$PWD
    scp hdfs-site.xml node03:$PWD
```

## hive启动命令    

```powershell
Hive数据仓库
    --启动HIve
    bin/hive
```

## hbase启动命令

```powershell
hbase启动
    --启动hbase集群
    hbase-all.sh
```

## flink集群启动命令及任务启动命令

```powershell
flink
    --启动flink
    start-cluster.sh
    ./flink run -c com.guigu.wc.StreamWordCount /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar /applog/flink/input.txt /applog/flink/output.csv
    ./flink run -m yarn-cluster -c com.guigu.wc.StreamWordCount /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar /applog/flink/input.txt /applog/flink/output.csv
    
    ./flink run -c com.guigu.wc.StreamWordCount_socket /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar 192.168.75.100 7777 /applog/flink/output.csv
    ./flink run -m yarn-cluster -c com.guigu.wc.StreamWordCount_socket /runjar/FlinkTourtourial-1.0-SNAPSHOT.jar 192.168.75.100 7777 /applog/flink/output.csv
    bin/flink run /export/servers/flink-1.6.0/examples/batch/WordCount.jar --input hdfs://node-1:9000/test/input/wordcount.txt --output hdfs://node-1:9000/test/output/result.txt

--yarn
2) 启动 yarn-session
./yarn-session.sh -n 2 -s 2 -jm 1024 -tm 1024 -nm test -d
其中：
-n(--container)：TaskManager 的数量。
-s(--slots)： 每个 TaskManager 的 slot 数量，默认一个 slot 一个 core，默认每个
taskmanager 的 slot 的个数为 1，有时可以多一些 taskmanager，做冗余。
-jm：JobManager 的内存（单位 MB)。
-tm：每个 taskmanager 的内存（单位 MB)。
-nm：yarn 的 appName(现在 yarn 的 ui 上的名字)。
-d：后台执行。

```

## kafka后台启动命令

```powershell

kafka启动
    --启动
    bin/kafka-server-start.sh -daemon config/server.properties
```

## mapreduce

```powershell
--任务启动hive
yarn jar hadoop_hdfs_operate‐1.0‐SNAPSHOT.jar
cn.itcast.hdfs.demo1.JobMain
--应用提交
hadoop jar jar_name MainClass
```

## spark命令

### Local模式

```powershell
--启动 Local 环境 
bin/spark-shell
--验证Local环境是否成功
http://192.168.75.100:4040/jobs/
--程序验证
scala> sc.textFile("data/word.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_).collect
--结果
res1: Array[(String, Int)] = Array((Hello,2), (Scala,1), (Spark,1))
--应用提交
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master local[2] \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

### standalone模式

```powershell
--启动历史服务
sbin/start-history-server.sh
--启动集群
sbin/start-all.sh
--启动节点--高可用主备模式
sbin/start-master.sh
--停止集群
sbin/stop-all.sh
--应用提交
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://linux1:7077 \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
--提交应用到高可用集群
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://linux1:7077,linux2:7077 \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10

```

## Yarn模式

```powershell
--启动历史服务
sbin/start-history-server.sh
--启动集群
sbin/start-all.sh
--应用提交
bin/spark-submit \
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode client \
./examples/jars/spark-examples_2.12-3.0.0.jar \
10
```

## window模式

```powershell
--启动
bin 目录中的 spark-shell.cmd
--应用提交
spark-submit --class org.apache.spark.examples.SparkPi --master
local[2] ../examples/jars/spark-examples_2.12-3.0.0.jar 10
```

## flume启动

### 网络采集

```shell
bin/flume-ng agent -c conf -f conf/netcat-logger.conf -n a1 -Dflume.root.logger=INFO,console
```

- -c conf 指定flume自身的配置文件所在目录
- -f conf/netcat-logger.conf 指定我们所描述的采集方案
- -n al 指定我们agent的名字

netcat-logger.conf

```shell
# 定义这个agent中各组件的名字
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# 描述和配置source组件：r1
a1.sources.r1.type = netcat
a1.sources.r1.bind = 192.168.174.
a1.sources.r1.port = 44444
# 描述和配置sink组件：k1
a1.sinks.k1.type = logger
# 描述和配置channel组件，此处使用是内存缓存的方式
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
# 描述和配置source channel sink之间的连接关系
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

```



### 目录采集

spooldir.cof

```shell
# 配置三个组件的名称
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# 注意不能网监控目录中丢同名文件
# 配置source
a1.sources.r1.type = spooldir
al.sources.r1.spoolDir = /export/servers/dirfile
a1.sources.r1.fileHeader = true
# sink
a1.sources.r1.type = spooldir
a1.sources.r1.spoolDir = /export/servers/dirfile
a1.sources.r1.fileHeader = true
# Describe the sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.channel = c1
a1.sinks.k1.hdfs.path = hdfs://node01:8020/spooldir/files/%y-%m-%d/%H%M/
a1.sinks.k1.hdfs.filePrefix = events-
# 使用文件滚动
a1.sinks.k1.hdfs.round = true
# hdfs文件夹的滚动周期
a1.sinks.k1.hdfs.roundValue = 10
a1.sinks.k1.hdfs.roundUnit = minute
# 每个3秒钟产生一个新文件
a1.sinks.k1.hdfs.rollInterval = 3
# 文件（hdfs的临时文件）大小达到20字节产生新文件
a1.sinks.k1.hdfs.rollSize = 20
# hdfs临时文件大小达到5个event时产生新文件
a1.sinks.k1.hdfs.rollCount = 5
# 放入队列的event的个数，batchSize<transactionCapacity<capacity
a1.sinks.k1.hdfs.batchSize = 1
# 是否使用本地时间戳
a1.sinks.k1.hdfs.useLocalTimeStamp = true
#生成的文件类型，默认是Sequencefile，可用DataStream，则为普通文本
a1.sinks.k1.hdfs.fileType = DataStream
# 配置channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

启动实例

```shell
bin/flume-ng agent -c ./conf -f ./conf/sqooldir.conf -n a1 -Dflume.root.logger=INFO,console
```

### 文件监控采集

vim tail-file.conf

```shell
agent1.sources = source1
agent1.sinks = sink1
agent1.channels = channel1
# Describe/configure tail -F source1
agent1.sources.source1.type = exec
agent1.sources.source1.command = tail -F /export/servers/taillogs/access_log
agent1.sources.source1.channels = channel1
# Describe sink1
agent1.sinks.sink1.type = hdfs
#a1.sinks.k1.channel = c1
agent1.sinks.sink1.hdfs.path = hdfs://node01:8020/weblog/flume-collection/%y-%m-%d/%H-%M
agent1.sinks.sink1.hdfs.filePrefix = access_log
agent1.sinks.sink1.hdfs.maxOpenFiles = 5000
agent1.sinks.sink1.hdfs.batchSize= 100
agent1.sinks.sink1.hdfs.fileType = DataStream
agent1.sinks.sink1.hdfs.writeFormat =Text
agent1.sinks.sink1.hdfs.round = true
agent1.sinks.sink1.hdfs.roundValue = 10
agent1.sinks.sink1.hdfs.roundUnit = minute
agent1.sinks.sink1.hdfs.useLocalTimeStamp = true
# Use a channel which buffers events in memory
agent1.channels.channel1.type = memory
agent1.channels.channel1.keep-alive = 120
agent1.channels.channel1.capacity = 500000
agent1.channels.channel1.transactionCapacity = 600
# Bind the source and sink to the channel
agent1.sources.source1.channels = channel1
agent1.sinks.sink1.channel = channel1

```

启动命令

```shell
bin/flume-ng agent -c conf -f conf/tail-file.conf -n agent1 -Dflume.root.logger=INFO,console
```

### 文件采集到kafka

```properties
a1.sources = r1
a1.sinks = k1
a1.channels = c1

al.sources.r1.type = exec
a1.sources.r1.command = tail -F /dir/20220105/test.log
a1.sources.r1.shell = /bin/bash -c

al.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.bootstrap.servers = ip:port,ip1:port
al.sinks.k1.kafka.topic = FUN_TEST1
# 需要认证
a1.sinks.k1.kafka.producer.sasl.security.protocol = PLAINTEXT
a1.sinks.k1.kafka.flumeBathSize = 38
al.sinks.k1.kafka.producer.linger.ms = 10

a1.channel.c1.type = memory
al.channel.c1.capacity = 100
a1.channel.c1.transactionCapacity = 1000

al.sources.r1.channels = c1
a1.sinks.k1.channels = c1
```



### 启动报错由于hbase

![](/flume.png)

### flume集群

node01:vim agent.conf

```shell
#agent1 name
agent1.channels = c1
agent1.sources = r1
agent1.sinks = k1 k2
#
##set gruop
agent1.sinkgroups = g1
#
agent1.sources.r1.channels = c1
agent1.sources.r1.type = exec
agent1.sources.r1.command = tail -F /export/servers/taillogs/access_log
#
##set channel
agent1.channels.c1.type = memory
agent1.channels.c1.capacity = 1000
agent1.channels.c1.transactionCapacity = 100
#
## set sink1
agent1.sinks.k1.channel = c1
agent1.sinks.k1.type = avro
agent1.sinks.k1.hostname = node02
agent1.sinks.k1.port = 52020
#
## set sink2
agent1.sinks.k2.channel = c1
agent1.sinks.k2.type = avro
agent1.sinks.k2.hostname = node03
agent1.sinks.k2.port = 52020
#
##set sink group
agent1.sinkgroups.g1.sinks = k1 k2
#
##set failover
agent1.sinkgroups.g1.processor.type = failover
agent1.sinkgroups.g1.processor.priority.k1 = 10
agent1.sinkgroups.g1.processor.priority.k2 = 1
agent1.sinkgroups.g1.processor.maxpenalty = 10000

```

node02: vim collector.conf

```shell
#set Agent name
a1.sources = r1
a1.channels = c1
a1.sinks = k1
#
##set channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
#
## other node,nna to nns
a1.sources.r1.type = avro
a1.sources.r1.bind = node02
a1.sources.r1.port = 52020
a1.sources.r1.channels = c1
#
##set sink to hdfs
a1.sinks.k1.type=hdfs
a1.sinks.k1.hdfs.path= hdfs://node01:8020/flume/failover/
a1.sinks.k1.hdfs.fileType=DataStream
a1.sinks.k1.hdfs.writeFormat=TEXT
a1.sinks.k1.hdfs.rollInterval=10
a1.sinks.k1.channel=c1
a1.sinks.k1.hdfs.filePrefix=%Y-%m-%d
```

node03: vim collector.cof

```shell
#set Agent name
a1.sources = r1
a1.channels = c1
a1.sinks = k1
#
##set channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
#
## other node,nna to nns
a1.sources.r1.type = avro
a1.sources.r1.bind = node03
a1.sources.r1.port = 52020
a1.sources.r1.channels = c1
#
##set sink to hdfs
a1.sinks.k1.type=hdfs
a1.sinks.k1.hdfs.path= hdfs://node01:8020/flume/failover/
a1.sinks.k1.hdfs.fileType=DataStream
a1.sinks.k1.hdfs.writeFormat=TEXT
a1.sinks.k1.hdfs.rollInterval=10
a1.sinks.k1.channel=c1
a1.sinks.k1.hdfs.filePrefix=%Y-%m-%d

```

启动顺序node03-->node02-->node01

## docker

### 安装docker

```shell
# 1、yum 包更新到最新 
yum update
# 2、安装需要的软件包， yum-util 提供yum-config-manager功能，另外两个是devicemapper驱动依赖的 
yum install -y yum-utils device-mapper-persistent-data lvm2
# 3、 设置yum源
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
# 4、 安装docker，出现输入的界面都按 y 
yum install -y docker-ce
# 5、 查看docker版本，验证是否验证成功
docker -v
```

### docker问题

#### docker安装镜像问题

1.卸载docker旧版本：

```shell
sudo yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-selinux \
                  docker-engine-selinux \
                  docker-engine
```


2.安装相关工具类：

```shell
sudo yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2
```


3.配置docker仓库：

```shell
sudo yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
会报以下错误：
Loaded plugins: fastestmirror
adding repo from: https://download.docker.com/linux/centos/docker-ce.repo
grabbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo
Could not fetch/save url https://download.docker.com/linux/centos/docker-ce.repo to file /etc/yum.repos.d/docker-ce.repo
: [Errno 14] curl#35 - "TCP connection reset by peer
```

这是由于国内访问不到docker官方镜像的缘故
可以通过aliyun的源来完成：

```shell
sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
出现以下内容则表示docker仓库配置成功：
Loaded plugins: fastestmirror
adding repo from: http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
grabbing file http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo to /etc/yum.repos.d/docker-ce.repo
repo saved to /etc/yum.repos.d/docker-ce.repo
```

4.安装docker

     sudo yum install docker-ce
    出现以下异常：
    Loaded plugins: fastestmirror
    base
    https://download-stage.docker.com/linux/centos/7/x86_64/stable/repodata/repomd.xml: [Errno 14] curl#35 - "TCP connection reset by peer"
    Trying other mirror.
    
     One of the configured repositories failed (Docker CE Stable - x86_64),
     and yum doesn't have enough cached data to continue. At this point the only
     safe thing yum can do is fail. There are a few ways to work "fix" this:
     1. Contact the upstream for the repository and get them to fix the problem.
    
     2. Reconfigure the baseurl/etc. for the repository, to point to a working
        upstream. This is most often useful if you are using a newer
        distribution release than is supported by the repository (and the
        packages for the previous distribution release still work).
    
     3. Run the command with the repository temporarily disabled
            yum --disablerepo=docker-ce-stable ...
    
     4. Disable the repository permanently, so yum won't use it by default. Yum
        will then just ignore the repository until you permanently enable it
        again or use --enablerepo for temporary usage:
    
            yum-config-manager --disable docker-ce-stable
        or
            subscription-manager repos --disable=docker-ce-stable
    
     5. Configure the failing repository to be skipped, if it is unavailable.
        Note that yum will try to contact the repo. when it runs most commands,
        so will have to try and fail each time (and thus. yum will be be much
        slower). If it is a very temporary problem though, this is often a nice
        compromise:
    
            yum-config-manager --save --setopt=docker-ce-stable.skip_if_unavailable=true
            failure: repodata/repomd.xml from docker-ce-stable: [Errno 256] No more mirrors to try.
    https://download-stage.docker.com/linux/centos/7/x86_64/stable/repodata/repomd.xml: [Errno 14] curl#35 - "TCP connection reset by peer"


分析原因为：阿里的镜像库文件也指向docker官方库，所以需要修改库文件

```shell
sudo vim /etc/yum.repos.d/docker-ce.repo
通过命令把https://download-stage.docker.com替换为http://mirrors.aliyun.com/docker-ce
命令如下：
:%s#https://download-stage.docker.com#http://mirrors.aliyun.com/docker-ce#g
```

在执行安装docker的部分妈可安装成功。

```shell
sudo yum install docker-ce
内容如下：
Installed:
  docker-ce.x86_64 0:18.03.0.ce-1.el7.centos

Dependency Installed:
  audit-libs-python.x86_64 0:2.7.6-3.el7 checkpolicy.x86_64 0:2.5-4.el7   container-selinux.noarch 2:2.42-1.gitad8f0f7.el7 libcgroup.x86_64 0
  libtool-ltdl.x86_64 0:2.4.2-22.el7_3   pigz.x86_64 0:2.3.3-1.el7.centos policycoreutils-python.x86_64 0:2.5-17.1.el7     python-IPy.noarch

Complete!
```

5.验证docker安装成功：

启动docker：

```shell
sudo systemctl start docker
验证docker:
sudo docker run hello-world
则会出现以下异常：
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
9bb5a5d4561a: Pulling fs layer
docker: error pulling image configuration: Get https://dseasb33srnrn.cloudfront.net/registry-v2/docker/registry/v2/blobs/sha256/e3/e38bc07ac18e
See 'docker run --help'.
```

此错误也是网络问题：国内无法访问dockerhub
配置阿里云的docker镜像库：在阿里云开通容器镜像服务拿到加速地址在执行以下命令：

```shell
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://｛自已的编码｝.mirror.aliyuncs.com"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker
```


再次验证docker:

```shell
sudo docker run hello-world
出现以下内容则表示安装成功：
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
9bb5a5d4561a: Pull complete
Digest: sha256:f5233545e43561214ca4891fd1157e1c3c563316ed8e237750d59bde73361e77
Status: Downloaded newer image for hello-world:latest

Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:

  1. The Docker client contacted the Docker daemon.
  2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
     (amd64)
  3. The Docker daemon created a new container from that image which runs the
     executable that produces the output you are currently reading.
  4. The Docker daemon streamed that output to the Docker client, which sent it
     to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
```

#### 加速器

1.登陆阿里云领取自己的加速器

​	https://6u9wyxo8.mirror.aliyuncs.com

2.配置镜像加速器

针对Docker客户端版本大于 1.10.0 的用户

您可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器

```
sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://6u9wyxo8.mirror.aliyuncs.com"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker
```

#### 停止问题

```shell
# /etc/init.d/docker stop

[....] Stopping docker (via systemctl): docker.serviceWarning: Stopping docker.service, but it can still be activated by:
  docker.socket
. ok 
```

解决方法

```shell
sudo systemctl stop docker.socket
```



### docker命令

#### 服务启动命令

```shell
--启动docker
systemctl start docker
--查看docker的状态
systemctl status docker
--停止docker
systemctl stop docker
--重启docker
systemctl restart docker
--设置开启启动docker服务
systemctl enable docker
```

#### Docker镜像相关命令

```shell
--查看镜像
docker images 
--查看所用镜像的id
docker images -q

--搜索镜像
docker search redis

--拉取镜像
docker pull redis:3.2

--删除镜像
docker rmi 镜像id
docker rmi redis:latest
--删除所有镜像
docker rmi 	`docker images -q`
```

#### Docker容器相关命令

```shell
--查看容器
--查看正在运行的容器
docker ps
--查看全部容器
docker ps -a

--创建容器
docker run -it --name=c1 centos:7 /bin/bash #退出容器关闭、进入;前端
--创建容器
docker run -id --name=c2 centos:7# 未进入容器 ,后端运行

--进入容器
docker exec -it c2 /bin/bash

--退出容器
exit

--启动容器
docker start c2

--停止容器
docker stop c2

--删除容器
docker rm 容器名称/容器id
--删除所有容器
docker rm `docker ps -aq`

--查看容器信息
docker inspect c2
```

